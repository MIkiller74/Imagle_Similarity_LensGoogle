{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g612UVuGSM1Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB1tAzVjSaMp",
        "outputId": "38565330-02d5-4e5d-90f7-072a5c2df990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "cifar100 = tf.keras.datasets.cifar100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "input_shape = x_train.shape[1:]  # (32, 32, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7vsqTgtScn5"
      },
      "outputs": [],
      "source": [
        "def build_improved_autoencoder(input_shape):\n",
        "    # Encoder\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)  # Output with 3 channels for RGB\n",
        "\n",
        "    # Autoencoder and Encoder Models\n",
        "    autoencoder = Model(inputs, decoded)\n",
        "    encoder = Model(inputs, encoded)\n",
        "\n",
        "    return autoencoder, encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teyeIkOQSf3a",
        "outputId": "14a95c9e-7a57-4693-c609-80e27b9da309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - loss: 0.0153 - val_loss: 0.0065\n",
            "Epoch 2/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14ms/step - loss: 0.0058 - val_loss: 0.0059\n",
            "Epoch 3/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0046\n",
            "Epoch 4/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 5/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0038\n",
            "Epoch 6/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0031\n",
            "Epoch 7/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 0.0032 - val_loss: 0.0030\n",
            "Epoch 8/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "Epoch 9/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 10/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0027 - val_loss: 0.0029\n",
            "Epoch 11/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 12/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 13/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 14/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0397\n",
            "Epoch 15/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 16/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 17/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 18/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 19/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 20/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0021 - val_loss: 0.0022\n",
            "Epoch 21/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 22/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 23/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 24/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 25/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 26/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 27/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 28/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 29/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 30/30\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0019 - val_loss: 0.0020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7972d3d954e0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "autoencoder, encoder = build_improved_autoencoder(input_shape)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.fit(x_train, x_train, epochs=30, batch_size=64, validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHqMhyA3Tb3m"
      },
      "outputs": [],
      "source": [
        "def evaluate_similarity(encoder, query_image, dataset, ground_truth_labels):\n",
        "\n",
        "    query_embedding = encoder.predict(np.expand_dims(query_image, axis=0))\n",
        "    dataset_embeddings = encoder.predict(dataset)\n",
        "\n",
        "\n",
        "    query_embedding = query_embedding.reshape(-1)\n",
        "    dataset_embeddings = dataset_embeddings.reshape(dataset_embeddings.shape[0], -1)\n",
        "\n",
        "\n",
        "    similarities = cosine_similarity(query_embedding.reshape(1, -1), dataset_embeddings)\n",
        "    similarities = similarities.flatten()\n",
        "\n",
        "\n",
        "    sorted_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "\n",
        "    query_label = ground_truth_labels[np.argmax(similarities)]\n",
        "\n",
        "\n",
        "    relevant_labels = [1 if ground_truth_labels[i] == query_label else 0 for i in sorted_indices]\n",
        "\n",
        "\n",
        "    top_k = 5\n",
        "    retrieved_labels = relevant_labels[:top_k]\n",
        "\n",
        "\n",
        "    precision = np.sum(retrieved_labels) / top_k\n",
        "    recall = np.sum(retrieved_labels) / np.sum(relevant_labels)\n",
        "    retrieval_accuracy = np.mean(retrieved_labels)\n",
        "\n",
        "    return precision, recall, retrieval_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v9Q7MCWTfG0",
        "outputId": "faa7f273-b3f5-4573-a780-fc0881ab99a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Precision: 0.2000\n",
            "Recall: 0.0100\n",
            "Retrieval Accuracy: 0.2000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "query_image = x_test[0]\n",
        "dataset = x_test\n",
        "ground_truth_labels = y_test.flatten()\n",
        "\n",
        "\n",
        "precision, recall, retrieval_accuracy = evaluate_similarity(encoder, query_image, dataset, ground_truth_labels)\n",
        "\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Retrieval Accuracy: {retrieval_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOC86VbDUGlE",
        "outputId": "36d7827a-d639-4b9d-c7e3-21ee90461d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "autoencoder.save('autoencoder_model_CIFAR_t2_cf.h5')\n",
        "encoder.save('encoder_model_CIFAR_t2_cf.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quG7OLSNUSyV",
        "outputId": "e43cf23e-27e2-49b6-e2f4-d5f05a6cce74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.2000\n",
            "Recall: 0.0100\n",
            "Retrieval Accuracy: 0.2000\n"
          ]
        }
      ],
      "source": [
        "loaded_autoencoder = tf.keras.models.load_model('autoencoder_model_CIFAR_t2.h5')\n",
        "loaded_encoder = tf.keras.models.load_model('encoder_model_CIFAR_t2.h5')\n",
        "\n",
        "precision, recall, retrieval_accuracy = evaluate_similarity(loaded_encoder, query_image, dataset, ground_truth_labels)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Retrieval Accuracy: {retrieval_accuracy:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}